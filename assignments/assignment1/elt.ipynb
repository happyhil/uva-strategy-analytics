{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breathing-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inner-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_pipeline(dataf):\n",
    "    \n",
    "    return dataf.copy()\n",
    "\n",
    "def select_initial_columns(dataf,\n",
    "                           columns=[\n",
    "                                'dealnumber',\n",
    "                                'dealstatus',\n",
    "                                'withdrawn_date',\n",
    "                                'completed_date',\n",
    "                                'target_sector',\n",
    "                                'acquiror_sector',\n",
    "                                'deal_type',\n",
    "                                'bid_premium_rumour_date',\n",
    "                                'bid_premium_announced_date',\n",
    "                                'initial_stake',\n",
    "                                'acquiror_country',\n",
    "                                'target_country',\n",
    "                                'predeal_target_market_cap',\n",
    "                                'predeal_acquiror_market_cap',\n",
    "                                'predeal_acquiror_net_assets',\n",
    "                                'predeal_target_total_assets',\n",
    "                                'predeal_target_ebit',\n",
    "                                'target_name',\n",
    "                                'acquiror_name',\n",
    "                           ]):\n",
    "    \n",
    "    dataf = dataf.drop(columns=['Unnamed: 0'])\n",
    "    dataf.columns = columns\n",
    "    return dataf\n",
    "\n",
    "def select_initial_rows(dataf):\n",
    "    \n",
    "    dataf = dataf.loc[lambda x: ~x['dealnumber'].isnull()].copy()\n",
    "    dataf['dealnumber'] = pd.factorize(dataf['dealnumber'])[0] + 1\n",
    "    return dataf\n",
    "\n",
    "def delete_na(dataf):\n",
    "\n",
    "    for c in dataf.columns:\n",
    "        try:\n",
    "            dataf[c] = dataf[c].str.replace('n.a.', np.nan)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            dataf[c] = dataf[c].replace('n.a.', np.nan)\n",
    "        except:\n",
    "            pass   \n",
    "    return dataf\n",
    "\n",
    "def feature_generation(dataf):\n",
    "    \n",
    "    dataf['target_sector'] = dataf['target_sector'].str.split(',').str[0]\n",
    "    dataf['acquiror_sector'] = dataf['acquiror_sector'].str.split(',').str[0]\n",
    "    dataf['same_sector'] = False\n",
    "    dataf.loc[lambda x: x['target_sector']==x['acquiror_sector'], 'same_sector'] = True\n",
    "    \n",
    "    dataf['same_country'] = False\n",
    "    dataf.loc[lambda x: x['target_country']==x['acquiror_country'], 'same_country'] = True\n",
    "    \n",
    "    dataf['relative_size'] = dataf['predeal_target_market_cap'] / dataf['predeal_acquiror_market_cap']\n",
    "    \n",
    "    dataf['roa_target'] = round(dataf['predeal_target_ebit'] / dataf['predeal_target_total_assets'], 6)\n",
    "    \n",
    "    dataf['acquiror_size'] = dataf['predeal_acquiror_market_cap']\n",
    "    dataf['bid_premium'] = dataf['bid_premium_rumour_date']\n",
    "    dataf['acquiror_free_cashflow'] = dataf['predeal_acquiror_net_assets']\n",
    "    \n",
    "    return dataf\n",
    "\n",
    "def feature_selection(dataf,\n",
    "                      columns=[\n",
    "                          'dealstatus',\n",
    "                          'same_sector',\n",
    "                          'same_country',\n",
    "                          'target_sector',\n",
    "                          'acquiror_sector',\n",
    "                          'deal_type',\n",
    "                          'relative_size',\n",
    "                          'acquiror_size',\n",
    "                          'roa_target',\n",
    "                          'bid_premium',\n",
    "                          'initial_stake',\n",
    "                          'acquiror_free_cashflow',\n",
    "                      ]):\n",
    "    \n",
    "    return dataf[columns]\n",
    "\n",
    "def report_empty_rows(dataf):\n",
    "    \n",
    "    for c in dataf.columns:\n",
    "        print(f'{c}: {round(len(dataf.loc[lambda x: ~x[c].isnull()]) / len(dataf), 2)}')\n",
    "\n",
    "def filter_out_empty_rows(dataf, columns=None):\n",
    "    \n",
    "    if columns == None:\n",
    "        for c in dataf.columns:\n",
    "            dataf = dataf.loc[lambda x: ~x[c].isnull()]\n",
    "            dataf = dataf.loc[lambda x: x[c]!=-np.inf]\n",
    "            dataf = dataf.loc[lambda x: x[c]!=-np.inf] \n",
    "    else:\n",
    "        for c in columns:\n",
    "            dataf = dataf.loc[lambda x: ~x[c].isnull()]\n",
    "            dataf = dataf.loc[lambda x: x[c]!=-np.inf]\n",
    "            dataf = dataf.loc[lambda x: x[c]!=-np.inf] \n",
    "    return dataf\n",
    "\n",
    "def select_columns(dataf, columns):\n",
    "    \n",
    "    return dataf[columns]\n",
    "\n",
    "def clean_sector(dataf):\n",
    "    \n",
    "    for c in ['target_sector', 'acquiror_sector']:\n",
    "        dataf[c] = dataf[c].str.split(' ').str[0]\n",
    "    return dataf\n",
    "\n",
    "def transform_low_frequent_sectors(dataf, new_value):\n",
    "    \n",
    "    for c in ['target_sector', 'acquiror_sector']:\n",
    "        dataf.loc[lambda x: x.groupby([c])['dealstatus'].transform('count')<10, c] = new_value\n",
    "    return dataf\n",
    "\n",
    "def remove_roa_outliers(dataf):\n",
    "    \n",
    "    highest = dataf['roa_target'].quantile(0.97)\n",
    "    lowest = dataf['roa_target'].quantile(0.03)\n",
    "    return dataf.loc[lambda x: (x['roa_target']>lowest) & (x['roa_target']<highest)]\n",
    "\n",
    "def define_dummies(dataf, columns):\n",
    "    \n",
    "    for c in columns:\n",
    "        for u in dataf[c].unique():\n",
    "            dummy_col_name = f\"{c}_{u.lower().replace(' ', '_')}\"\n",
    "            dataf[dummy_col_name] = False\n",
    "            dataf.loc[lambda x: x[c]==u, dummy_col_name] = True\n",
    "            \n",
    "    return dataf.drop(columns=columns)\n",
    "\n",
    "def clean_dealtype(dataf):\n",
    "    \n",
    "    dataf['deal_type'] = dataf['deal_type'].str.lower()\n",
    "    dataf.loc[lambda x: x['deal_type'].str.contains('acquisition increased'), 'deal_type_clean'] = 'acquisition_stake_increased'\n",
    "    dataf.loc[lambda x: (x['deal_type'].str.contains('100%'))\n",
    "                      & (x['deal_type'].str.contains('acquisition')), 'deal_type_clean'] = 'acquisition_100%'\n",
    "    dataf.loc[lambda x: (x['deal_type'].str.contains('acquisition'))\n",
    "                      & (x['deal_type_clean'].isnull()), 'deal_type_clean'] = 'acquisition_other%'\n",
    "    dataf.loc[lambda x: (x['deal_type'].str.contains('merger'))\n",
    "                      & (x['deal_type_clean'].isnull()), 'deal_type_clean'] = 'merger'\n",
    "    dataf.loc[lambda x: x['deal_type_clean'].isnull(), 'deal_type_clean'] = 'other'\n",
    "    dataf['deal_type'] = dataf['deal_type_clean']\n",
    "    \n",
    "    return dataf.drop(columns=['deal_type_clean'])\n",
    "\n",
    "def y_to_bin(dataf, y='dealstatus'):\n",
    "    \n",
    "    dataf[f'{y}_new'] = 0\n",
    "    dataf.loc[lambda x: x[y]=='Completed', f'{y}_new'] = 1\n",
    "    dataf[y] = dataf[f'{y}_new']\n",
    "    return dataf.drop(columns=[f'{y}_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "structural-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfraw = pd.read_excel('input/Data_set_NAFTA_EU_acquiror only.xls', sheet_name='Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "similar-monte",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3e2b9bfe4508>:42: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataf[c] = dataf[c].str.replace('n.a.', np.nan)\n"
     ]
    }
   ],
   "source": [
    "dfclean = (dfraw.pipe(start_pipeline)\n",
    "           .pipe(select_initial_columns)\n",
    "           .pipe(select_initial_rows)\n",
    "           .pipe(delete_na)\n",
    "           .pipe(feature_generation)\n",
    "           .pipe(clean_sector)\n",
    "           .pipe(feature_selection)\n",
    "          )\n",
    "\n",
    "columns = [\n",
    "    'dealstatus',\n",
    "    'same_sector',\n",
    "    'same_country',\n",
    "    'target_sector',\n",
    "    'acquiror_sector',\n",
    "    'deal_type',\n",
    "    'roa_target',\n",
    "    'initial_stake',\n",
    "]\n",
    "\n",
    "dummy_columns = [\n",
    "    'target_sector',\n",
    "    'acquiror_sector',\n",
    "    'deal_type'\n",
    "]\n",
    "\n",
    "dfprepped = (dfclean.pipe(filter_out_empty_rows, columns)\n",
    "             .pipe(select_columns, columns)\n",
    "             .pipe(clean_dealtype)\n",
    "             .pipe(remove_roa_outliers)\n",
    "             .pipe(transform_low_frequent_sectors, 'Other')\n",
    "             .pipe(y_to_bin)\n",
    "            )\n",
    "\n",
    "dfprepped_featured = (dfclean.pipe(filter_out_empty_rows, columns)\n",
    "             .pipe(select_columns, columns)\n",
    "             .pipe(clean_dealtype)\n",
    "             .pipe(remove_roa_outliers)\n",
    "             .pipe(transform_low_frequent_sectors, 'Other')\n",
    "             .pipe(define_dummies, dummy_columns)\n",
    "             .pipe(y_to_bin)\n",
    "            )\n",
    "\n",
    "dfprepped.to_csv('input/analysis_features_dataset.csv', index=False)\n",
    "dfprepped_featured.to_csv('input/final_featured_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "photographic-color",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- column completeness beforing checking:\n",
      "dealstatus: 1.0\n",
      "same_sector: 1.0\n",
      "same_country: 1.0\n",
      "target_sector: 0.97\n",
      "acquiror_sector: 0.97\n",
      "deal_type: 1.0\n",
      "relative_size: 0.16\n",
      "acquiror_size: 0.24\n",
      "roa_target: 0.72\n",
      "bid_premium: 0.29\n",
      "initial_stake: 1.0\n",
      "acquiror_free_cashflow: 0.34\n"
     ]
    }
   ],
   "source": [
    "print('-- column completeness beforing checking:')\n",
    "report_empty_rows(dfclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incredible-railway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n rows before filtering on completeness & outliers: 885\n",
      "n rows after filtering on completeness & outliers: 564\n"
     ]
    }
   ],
   "source": [
    "print(f'n rows before filtering on completeness & outliers: {len(dfclean)}')\n",
    "print(f'n rows after filtering on completeness & outliers: {len(dfprepped_featured)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
