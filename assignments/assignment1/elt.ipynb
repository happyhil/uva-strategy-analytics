{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_pipeline(dataf):\n",
    "    \n",
    "    return dataf.copy()\n",
    "\n",
    "def select_initial_columns(dataf,\n",
    "                           columns=[\n",
    "                                'dealnumber',\n",
    "                                'dealstatus',\n",
    "                                'withdrawn_date',\n",
    "                                'completed_date',\n",
    "                                'target_major_sector',\n",
    "                                'acquiror_major_sector',\n",
    "                                'deal_type',\n",
    "                                'bid_premium_rumour_date',\n",
    "                                'bid_premium_announced_date',\n",
    "                                'initial_stake',\n",
    "                                'acquiror_country',\n",
    "                                'target_country',\n",
    "                                'predeal_target_market_cap',\n",
    "                                'predeal_acquiror_market_cap',\n",
    "                                'predeal_acquiror_net_assets',\n",
    "                                'predeal_target_total_assets',\n",
    "                                'predeal_target_ebit',\n",
    "                                'target_name',\n",
    "                                'acquiror_name',\n",
    "                           ]):\n",
    "    \n",
    "    dataf = dataf.drop(columns=['Unnamed: 0'])\n",
    "    dataf.columns = columns\n",
    "    return dataf\n",
    "\n",
    "def select_initial_rows(dataf):\n",
    "    \n",
    "    dataf = dataf.loc[lambda x: ~x['dealnumber'].isnull()].copy()\n",
    "    dataf['dealnumber'] = pd.factorize(dataf['dealnumber'])[0] + 1\n",
    "    return dataf\n",
    "\n",
    "def delete_na(dataf):\n",
    "\n",
    "    for c in dataf.columns:\n",
    "        try:\n",
    "            dataf[c] = dataf[c].str.replace('n.a.', np.nan)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            dataf[c] = dataf[c].replace('n.a.', np.nan)\n",
    "        except:\n",
    "            pass   \n",
    "    return dataf\n",
    "\n",
    "def feature_generation(dataf):\n",
    "    \n",
    "    dataf['target_major_sector'] = dataf['target_major_sector'].str.split(',').str[0]\n",
    "    dataf['acquiror_major_sector'] = dataf['acquiror_major_sector'].str.split(',').str[0]\n",
    "    dataf['same_sector'] = False\n",
    "    dataf.loc[lambda x: x['target_major_sector']==x['acquiror_major_sector'], 'same_sector'] = True\n",
    "    \n",
    "    dataf['same_country'] = False\n",
    "    dataf.loc[lambda x: x['target_country']==x['acquiror_country'], 'same_country'] = True\n",
    "    \n",
    "    dataf['relative_size'] = dataf['predeal_target_market_cap'] / dataf['predeal_acquiror_market_cap']\n",
    "    \n",
    "    dataf['roa_target'] = round(dataf['predeal_target_ebit'] / dataf['predeal_target_total_assets'], 6)\n",
    "    \n",
    "    dataf['acquiror_size'] = dataf['predeal_acquiror_market_cap']\n",
    "    dataf['bid_premium'] = dataf['bid_premium_rumour_date']\n",
    "    dataf['acquiror_free_cashflow'] = dataf['predeal_acquiror_net_assets']\n",
    "    \n",
    "    return dataf\n",
    "\n",
    "def feature_selection(dataf,\n",
    "                      columns=[\n",
    "                          'dealstatus',\n",
    "                          'same_sector',\n",
    "                          'same_country',\n",
    "                          'target_major_sector',\n",
    "                          'acquiror_major_sector',\n",
    "                          'deal_type',\n",
    "                          'relative_size',\n",
    "                          'acquiror_size',\n",
    "                          'roa_target',\n",
    "                          'bid_premium',\n",
    "                          'initial_stake',\n",
    "                          'acquiror_free_cashflow',\n",
    "                      ]):\n",
    "    \n",
    "    return dataf[columns]\n",
    "\n",
    "def report_empty_rows(dataf):\n",
    "    \n",
    "    for c in dataf.columns:\n",
    "        print(f'{c}: {round(len(dataf.loc[lambda x: ~x[c].isnull()]) / len(dataf), 2)}')\n",
    "\n",
    "def filter_out_empty_rows(dataf, columns=None):\n",
    "    \n",
    "    if columns == None:\n",
    "        for c in dataf.columns:\n",
    "            dataf = dataf.loc[lambda x: ~x[c].isnull()]\n",
    "            dataf = dataf.loc[lambda x: x[c]!=-np.inf]\n",
    "            dataf = dataf.loc[lambda x: x[c]!=-np.inf] \n",
    "    else:\n",
    "        for c in columns:\n",
    "            dataf = dataf.loc[lambda x: ~x[c].isnull()]\n",
    "            dataf = dataf.loc[lambda x: x[c]!=-np.inf]\n",
    "            dataf = dataf.loc[lambda x: x[c]!=-np.inf] \n",
    "    return dataf\n",
    "\n",
    "def select_columns(dataf, columns):\n",
    "    \n",
    "    return dataf[columns]\n",
    "\n",
    "def define_dummies(dataf, columns):\n",
    "    \n",
    "    for c in columns:\n",
    "        for u in dataf[c].unique():\n",
    "            dummy_col_name = f\"{c}_{u.lower().replace(' ', '_')}\"\n",
    "            dataf[dummy_col_name] = False\n",
    "            dataf.loc[lambda x: x[c]==u, dummy_col_name] = True\n",
    "            \n",
    "    return dataf.drop(columns=columns)\n",
    "\n",
    "def clean_dealtype(dataf):\n",
    "    \n",
    "    dataf['deal_type'] = dataf['deal_type'].str.lower()\n",
    "    dataf.loc[lambda x: x['deal_type'].str.contains('acquisition increased'), 'deal_type_clean'] = 'acquisition_stake_increased'\n",
    "    dataf.loc[lambda x: (x['deal_type'].str.contains('100%'))\n",
    "                      & (x['deal_type'].str.contains('acquisition')), 'deal_type_clean'] = 'acquisition_100%'\n",
    "    dataf.loc[lambda x: (x['deal_type'].str.contains('acquisition'))\n",
    "                      & (x['deal_type_clean'].isnull()), 'deal_type_clean'] = 'acquisition_other%'\n",
    "    dataf.loc[lambda x: (x['deal_type'].str.contains('merger'))\n",
    "                      & (x['deal_type_clean'].isnull()), 'deal_type_clean'] = 'merger'\n",
    "    dataf.loc[lambda x: x['deal_type_clean'].isnull(), 'deal_type_clean'] = 'other'\n",
    "    dataf['deal_type'] = dataf['deal_type_clean']\n",
    "    \n",
    "    return dataf.drop(columns=['deal_type_clean'])\n",
    "\n",
    "def y_to_bin(dataf, y='dealstatus'):\n",
    "    \n",
    "    dataf[f'{y}_new'] = 0\n",
    "    dataf.loc[lambda x: x[y]=='Completed', f'{y}_new'] = 1\n",
    "    dataf[y] = dataf[f'{y}_new']\n",
    "    return dataf.drop(columns=[f'{y}_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfraw = pd.read_excel('input/Data_set_NAFTA_EU_Acquiror or target.xls', sheet_name='Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfclean = (dfraw.pipe(start_pipeline)\n",
    "           .pipe(select_initial_columns)\n",
    "           .pipe(select_initial_rows)\n",
    "           .pipe(delete_na)\n",
    "           .pipe(feature_generation)\n",
    "           .pipe(feature_selection)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfclean.groupby('target_major_sector')[['dealstatus']].count()\n",
    "# dfclean.groupby('acquiror_major_sector')[['dealstatus']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_empty_rows(dfclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'dealstatus',\n",
    "    'same_sector',\n",
    "    'same_country',\n",
    "    'target_major_sector',\n",
    "#     'acquiror_major_sector',\n",
    "    'deal_type',\n",
    "    'roa_target',\n",
    "    'initial_stake',\n",
    "]\n",
    "\n",
    "dummy_columns = [\n",
    "    'target_major_sector',\n",
    "#     'acquiror_major_sector',\n",
    "    'deal_type'\n",
    "]\n",
    "\n",
    "dfprepped = (dfclean.pipe(filter_out_empty_rows, columns)\n",
    "             .pipe(select_columns, columns)\n",
    "             .pipe(clean_dealtype)\n",
    "             .pipe(define_dummies, dummy_columns)\n",
    "             .pipe(y_to_bin)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfprepped.to_csv('input/final_featured_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
